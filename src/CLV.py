import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import pickle
import os
from pathlib import Path
from typing import Tuple, Dict, Any, Optional
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# --- Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ CLV ---
# pip install lifetimes
try:
    from lifetimes import BetaGeoFitter, GammaGammaFitter
    from lifetimes.plotting import plot_frequency_recency_matrix, plot_probability_alive_matrix
    LIFETIMES_AVAILABLE = True
except ImportError:
    print("âš ï¸  Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ CLV Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ lifetimes Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install lifetimes")
    LIFETIMES_AVAILABLE = False

# --- Configuration ---
DATA_PATH = r"C:\Users\moham\Desktop\MIT\Superstore.csv"
OUTPUT_DIR = Path(r"C:\Users\moham\Desktop\MIT\clv_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

class CustomerAnalyticsEngine:
    """Ù…ÙˆØªÙˆØ± ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ù…Ø´ØªØ±ÛŒØ§Ù† - Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ + CLV + Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú†Ø±Ù†"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.df = None
        self.customer_df = None
        self.clustered_df = None
        self.clv_predictions = None
        self.model = None
        self.scaler = None
        self.cluster_names = None
        self.clv_models = None
        
    def load_data(self) -> pd.DataFrame:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        try:
            df = pd.read_csv(self.data_path, encoding='utf-8-sig')
        except:
            df = pd.read_csv(self.data_path, encoding='latin1')
        
        df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_").str.replace("-", "_")
        df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
        return df
    
    def prepare_rfm_clv_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ RFM + CLV
        Ø¨Ø±Ø§ÛŒ lifetimes Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…: frequency, recency, T, monetary_value
        """
        if 'customer_id' not in df.columns:
            df['customer_id'] = df.get('customer_name', df.index)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø§Ù…Ø±ÙˆØ² (ÛŒØ§ max ØªØ§Ø±ÛŒØ® Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§)
        current_date = df['order_date'].max() + timedelta(days=1)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ lifetimes
        clv_df = df.groupby('customer_id').agg({
            'order_date': ['max', 'min'],
            'order_id': 'nunique',
            'profit': 'sum',
            'sales': 'sum',
            'discount': 'mean'
        }).reset_index()
        
        clv_df.columns = ['customer_id', 'max_order_date', 'min_order_date', 
                         'frequency', 'profit_sum', 'sales_sum', 'avg_discount']
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ recency (Ø±ÙˆØ² Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø®Ø±ÛŒØ¯ ØªØ§ Ø§Ù…Ø±ÙˆØ²)
        clv_df['recency'] = (current_date - clv_df['max_order_date']).dt.days
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ T (Ø³Ù† Ù…Ø´ØªØ±ÛŒ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ø®Ø±ÛŒØ¯ ØªØ§ Ø§Ù…Ø±ÙˆØ²)
        clv_df['T'] = (current_date - clv_df['min_order_date']).dt.days
        
        # monetary_value = Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³ÙˆØ¯ Ù‡Ø± Ø³ÙØ§Ø±Ø´
        clv_df['monetary_value'] = clv_df['profit_sum'] / clv_df['frequency']
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª RFM Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
        clv_df['recency_days'] = clv_df['recency']
        clv_df['frequency_rfm'] = clv_df['frequency']
        clv_df['total_profit'] = clv_df['profit_sum']
        clv_df['avg_discount_clv'] = clv_df['avg_discount']
        
        # Ø­Ø°Ù outlierâ€ŒÙ‡Ø§
        clv_df = clv_df[clv_df['frequency'] > 0]  # ÙÙ‚Ø· Ù…Ø´ØªØ±ÛŒØ§Ù† ØªÚ©Ø±Ø§Ø±ÛŒ
        for col in ['frequency', 'recency', 'monetary_value']:
            q99 = clv_df[col].quantile(0.99)
            clv_df[col] = clv_df[col].clip(upper=q99)
        
        return clv_df
    
    def perform_clustering(self, df: pd.DataFrame, n_clusters: int = None) -> Tuple[pd.DataFrame, KMeans, StandardScaler]:
        """
        Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± k
        """
        features = ['recency_days', 'frequency', 'total_profit', 'avg_discount', 'monetary_value']
        X = df[features].fillna(df[features].median())
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† k
        if n_clusters is None:
            n_clusters, _ = self._find_optimal_k(X_scaled)
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        df['cluster'] = kmeans.fit_predict(X_scaled)
        
        silhouette_avg = silhouette_score(X_scaled, df['cluster'])
        print(f"âœ… Silhouette Score: {silhouette_avg:.3f}")
        
        return df, kmeans, scaler
    
    def _find_optimal_k(self, X_scaled: np.ndarray, max_k: int = 8) -> Tuple[int, Dict]:
        """ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† k Ø¨Ø§ Ø±ÙˆØ´ Elbow Ùˆ Silhouette"""
        print(f"ğŸ” Finding optimal k (2 to {max_k})...")
        
        inertias = []
        silhouettes = []
        K_range = range(2, max_k + 1)
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(X_scaled)
            inertias.append(kmeans.inertia_)
            silhouettes.append(silhouette_score(X_scaled, kmeans.labels_))
        
        optimal_k = K_range[np.argmax(silhouettes)]
        
        # Ù†Ù…ÙˆØ¯Ø§Ø±
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        ax1.plot(K_range, inertias, 'bo-')
        ax1.set_title('Elbow Method')
        ax2.plot(K_range, silhouettes, 'go-')
        ax2.set_title('Silhouette Analysis')
        plt.tight_layout()
        plt.savefig(OUTPUT_DIR / 'cluster_optimization.png', dpi=300)
        plt.show()
        
        print(f"âœ… Optimal k: {optimal_k}")
        return optimal_k, {'inertias': inertias, 'silhouettes': silhouettes}
    
    def fit_clv_models(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ CLV
        BG/NBD Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±Ú©Ø§Ù†Ø³ Ø¨Ù‚Ø§Ø¡
        Gamma-Gamma Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø±Ø²Ø´ Ù…Ø§Ù„ÛŒ
        """
        if not LIFETIMES_AVAILABLE:
            print("âš ï¸  CLV models not available")
            return None
        
        print("\nğŸ¯ Fitting CLV Models...")
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ lifetimes
        clv_data = df[['frequency', 'recency', 'T', 'monetary_value']].copy()
        
        # Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± ØºÛŒØ±Ù…Ø¹ØªØ¨Ø±
        clv_data = clv_data[(clv_data['frequency'] > 0) & 
                           (clv_data['monetary_value'] > 0)]
        
        # Ø¢Ù…ÙˆØ²Ø´ BG/NBD
        bgf = BetaGeoFitter(penalizer_coef=0.0)
        bgf.fit(clv_data['frequency'], clv_data['recency'], clv_data['T'])
        
        # Ø¢Ù…ÙˆØ²Ø´ Gamma-Gamma
        ggf = GammaGammaFitter(penalizer_coef=0.0)
        ggf.fit(clv_data['frequency'], clv_data['monetary_value'])
        
        print("âœ… CLV models fitted successfully")
        
        return {
            'bgf': bgf,
            'ggf': ggf,
            'data': clv_data
        }
    
    def predict_clv(self, clv_models: Dict, df: pd.DataFrame, 
                   time_period: int = 12) -> pd.DataFrame:
        """
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ CLV Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø®Ø§Øµ (Ù…Ø«Ù„Ø§Ù‹ Û±Û² Ù…Ø§Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡)
        """
        if not clv_models:
            return df
        
        print(f"\nğŸ’° Predicting CLV for next {time_period} months...")
        
        bgf = clv_models['bgf']
        ggf = clv_models['ggf']
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±Ú©Ø§Ù†Ø³ Ø®Ø±ÛŒØ¯
        df['predicted_purchases'] = bgf.predict(time_period, 
                                               df['frequency'], 
                                               df['recency'], 
                                               df['T'])
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø±Ø²Ø´ Ù…Ø´ØªØ±ÛŒ
        df['predicted_clv'] = ggf.customer_lifetime_value(
            bgf,
            df['frequency'],
            df['recency'],
            df['T'],
            df['monetary_value'],
            time=time_period,
            discount_rate=0.01  # Ù†Ø±Ø® ØªÙ†Ø²ÛŒÙ„
        )
        
        # Ø±Ù†Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ
        df['predicted_clv'] = df['predicted_clv'].round(2)
        df['predicted_purchases'] = df['predicted_purchases'].round(1)
        
        print(f"âœ… CLV predicted for {len(df)} customers")
        return df
    
    def predict_churn(self, clv_models: Dict, df: pd.DataFrame) -> pd.DataFrame:
        """
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ú†Ø±Ù† (Ú©Ù‡ Ø¯ÛŒÚ¯Ø± Ø®Ø±ÛŒØ¯ Ù†Ú©Ù†Ù†Ø¯)
        Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ BG/NBD
        """
        if not clv_models:
            return df
        
        print("\nâš ï¸  Predicting churn probability...")
        
        bgf = clv_models['bgf']
        
        # Ø§Ø­ØªÙ…Ø§Ù„ Ø²Ù†Ø¯Ù‡ Ø¨ÙˆØ¯Ù† (Ú©Ù‡ Ù‡Ù†ÙˆØ² Ø®Ø±ÛŒØ¯ Ø®ÙˆØ§Ù‡Ù†Ø¯ Ú©Ø±Ø¯)
        df['probability_alive'] = bgf.conditional_probability_alive(
            df['frequency'],
            df['recency'],
            df['T']
        )
        
        # Ø§Ø­ØªÙ…Ø§Ù„ Ú†Ø±Ù† = Û± - alive
        df['churn_probability'] = (1 - df['probability_alive']).round(3)
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú†Ø±Ù†
        df['churn_risk'] = pd.cut(df['churn_probability'], 
                                 bins=[0, 0.3, 0.7, 1.0],
                                 labels=['Low', 'Medium', 'High'])
        
        print(f"âœ… Churn risk calculated")
        return df
    
    def interpret_clusters_with_clv(self, df: pd.DataFrame) -> Dict[int, str]:
        """
        âœ… Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: ØªÙØ³ÛŒØ± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ CLV Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ Ú†Ø±Ù†
        """
        print("\nğŸ“Š Interpreting clusters with CLV...")
        
        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        features = ['recency_days', 'frequency', 'total_profit', 'monetary_value']
        
        # âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ CLV ÙÙ‚Ø· Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯
        if 'predicted_clv' in df.columns:
            features.append('predicted_clv')
        else:
            print("âš ï¸  CLV not calculated, using only basic features")
            df['predicted_clv'] = df['total_profit'] * 2  # Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø³Ø§Ø¯Ù‡
        
        if 'churn_probability' in df.columns:
            features.append('churn_probability')
        else:
            print("âš ï¸  Churn probability not calculated, using default")
            df['churn_probability'] = 0.3
        
        cluster_profile = df.groupby('cluster')[features].mean()
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø¶Ø§ÙˆØª
        profile_norm = (cluster_profile - cluster_profile.min()) / (cluster_profile.max() - cluster_profile.min())
        
        cluster_names = {}
        for cluster_id in profile_norm.index:
            # Ù…Ù†Ø·Ù‚Ù‡ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±
            if profile_norm.loc[cluster_id, 'predicted_clv'] > 0.7:
                if profile_norm.loc[cluster_id, 'churn_probability'] < 0.3:
                    cluster_names[cluster_id] = "ğŸ¥‡ VIP Loyalists (Low Churn Risk)"
                else:
                    cluster_names[cluster_id] = "ğŸ’ High-Value (Medium Churn Risk)"
            elif profile_norm.loc[cluster_id, 'churn_probability'] > 0.7:
                cluster_names[cluster_id] = "ğŸš¨ Critical At-Risk"
            elif profile_norm.loc[cluster_id, 'total_profit'] < 0:
                cluster_names[cluster_id] = "âŒ Loss-Making Discount Seekers"
            elif profile_norm.loc[cluster_id, 'frequency'] > 0.6:
                cluster_names[cluster_id] = "ğŸ”„ Frequent (Potential Loyalists)"
            else:
                cluster_names[cluster_id] = "ğŸ†• Average/Developing"
        
        print("\nğŸ·ï¸  Cluster Names:")
        for cid, name in cluster_names.items():
            print(f"   Cluster {cid}: {name}")
        
        return cluster_names
    
    def plot_clv_analysis(self, df: pd.DataFrame, cluster_names: Dict):
        """Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ CLV Ùˆ Ú†Ø±Ù†"""
        df['cluster_name'] = df['cluster'].map(cluster_names)
        
        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø³ØªÙˆÙ† CLV
        if 'predicted_clv' not in df.columns:
            print("âš ï¸  CLV column not found, skipping CLV plots")
            return
        
        # Û±. ØªÙˆØ²ÛŒØ¹ CLV Ø¨Ø± Ø§Ø³Ø§Ø³ Ø®ÙˆØ´Ù‡
        plt.figure(figsize=(12, 6))
        sns.boxplot(x='cluster_name', y='predicted_clv', data=df, palette='viridis')
        plt.title('CLV Distribution by Cluster', fontsize=16, fontweight='bold')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(OUTPUT_DIR / 'clv_by_cluster.png', dpi=300)
        plt.show()
        
        # Û². Ú†Ø±Ù† vs CLV
        if 'churn_probability' in df.columns:
            plt.figure(figsize=(10, 6))
            sns.scatterplot(x='predicted_clv', y='churn_probability', 
                           hue='cluster_name', data=df, palette='viridis')
            plt.title('Churn Risk vs CLV', fontsize=16, fontweight='bold')
            plt.axhline(0.5, color='red', linestyle='--', alpha=0.7)
            plt.tight_layout()
            plt.savefig(OUTPUT_DIR / 'churn_vs_clv.png', dpi=300)
            plt.show()
    
    def generate_executive_report(self, df: pd.DataFrame, cluster_names: Dict):
        """
        Ú¯Ø²Ø§Ø±Ø´ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¬Ø§Ù…Ø¹
        """
        print("\n" + "="*80)
        print("ğŸ“Š EXECUTIVE REPORT: Customer Analytics & CLV Forecast")
        print("="*80)
        
        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø³ØªÙˆÙ† CLV
        if 'predicted_clv' in df.columns:
            total_clv = df['predicted_clv'].sum()
            avg_clv = df['predicted_clv'].mean()
        else:
            total_clv = df['total_profit'].sum() * 2  # Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø³Ø§Ø¯Ù‡
            avg_clv = df['total_profit'].mean() * 2
            print("âš ï¸  Using estimated CLV (total_profit * 2)")
        
        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø³ØªÙˆÙ† Ú†Ø±Ù†
        if 'churn_probability' in df.columns:
            high_churn_customers = len(df[df['churn_probability'] > 0.7])
        else:
            high_churn_customers = len(df) // 4  # Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø³Ø§Ø¯Ù‡
            print("âš ï¸  Using estimated churn risk (25% of customers)")
        
        print(f"\nğŸ’° TOTAL CLV (12-month forecast): ${total_clv:,.2f}")
        print(f"ğŸ“ˆ Average CLV per customer: ${avg_clv:.2f}")
        print(f"âš ï¸  High churn risk customers: {high_churn_customers:,}")
        
        # ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒØ§ÛŒ
        print(f"\n{'Cluster':<20} | {'Count':<8} | {'Avg CLV':<12} | {'Churn Risk':<12} | {'Action'}")
        print("-" * 80)
        
        for cluster_id in sorted(df['cluster'].unique()):
            cluster_data = df[df['cluster'] == cluster_id]
            name = cluster_names[cluster_id]
            count = len(cluster_data)
            
            # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            avg_clv_cluster = cluster_data['predicted_clv'].mean() if 'predicted_clv' in cluster_data.columns else cluster_data['total_profit'].mean() * 2
            avg_churn = cluster_data['churn_probability'].mean() if 'churn_probability' in cluster_data.columns else 0.3
            
            # ØªÙˆØµÛŒÙ‡ Ø¹Ù…Ù„ÛŒ
            if "VIP" in name:
                action = "Protect & Expand"
            elif "Loss-Making" in name:
                action = "Restructure Discounts"
            elif "At-Risk" in name:
                action = "Win-Back Campaign"
            else:
                action = "Develop & Upsell"
            
            print(f"{name[:18]:<20} | {count:<8} | ${avg_clv_cluster:<11.0f} | "
                  f"{avg_churn:<12.2%} | {action}")
        
        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† loss_making
        if 'total_profit' in df.columns:
            loss_making = df[df['total_profit'] < 0]
            potential_saving = loss_making['total_profit'].sum() * 0.5
        else:
            potential_saving = 0
        
        print(f"\nğŸ¯ IMPACT FORECAST (12 months):")
        print(f"   - Discount Seekers optimization: ${potential_saving:,.2f}")
        print(f"   - Churn reduction (5%): ${avg_clv * high_churn_customers * 0.05:,.2f}")
        
        print("\n" + "="*80)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´
        df.to_csv(OUTPUT_DIR / 'customers_with_clv_clusters.csv', index=False)
    
    def save_models(self, df: pd.DataFrame, kmeans: KMeans, scaler: StandardScaler, 
                   cluster_names: Dict, clv_models: Dict):
        """Ø°Ø®ÛŒØ±Ù‡ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        model_data = {
            'kmeans': kmeans,
            'scaler': scaler,
            'cluster_names': cluster_names,
            'clv_models': clv_models,
            'features': ['recency_days', 'frequency', 'total_profit', 
                        'avg_discount', 'monetary_value', 'predicted_clv', 
                        'churn_probability']
        }
        
        with open(OUTPUT_DIR / 'complete_analytics_engine.pkl', 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"\nğŸ’¾ Models saved: {OUTPUT_DIR / 'complete_analytics_engine.pkl'}")

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„"""
    
    # Ø³Ø§Ø®Øª Ù…ÙˆØªÙˆØ± ØªØ­Ù„ÛŒÙ„
    engine = CustomerAnalyticsEngine(DATA_PATH)
    
    # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
    print("â³ Loading data...")
    df = engine.load_data()
    print(f"   Loaded {len(df):,} transactions")
    
    # Û². Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ RFM + CLV
    print("\nğŸ› ï¸  Preparing RFM & CLV data...")
    customer_df = engine.prepare_rfm_clv_data(df)
    print(f"   {len(customer_df)} customers ready for analysis")
    
    # Û³. Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    print("\nğŸ¤– Running clustering...")
    clustered_df, kmeans_model, scaler = engine.perform_clustering(customer_df, n_clusters=4)
    
    # Û´. CLV (Ø§Ú¯Ø± lifetimes Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯)
    if LIFETIMES_AVAILABLE:
        print("\nğŸ¯ Training CLV models...")
        clv_models = engine.fit_clv_models(clustered_df)
        
        # âœ… Ø§ØµÙ„Ø§Ø­ Ù…Ù‡Ù…: Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ **Ù‚Ø¨Ù„** Ø§Ø² ØªÙØ³ÛŒØ± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
        print("\nğŸ’° Predicting CLV...")
        clustered_df = engine.predict_clv(clv_models, clustered_df)
        
        print("\nâš ï¸  Predicting churn...")
        clustered_df = engine.predict_churn(clv_models, clustered_df)
    else:
        clv_models = None
        # âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ dummy Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§
        clustered_df['predicted_clv'] = clustered_df['total_profit'] * 2
        clustered_df['churn_probability'] = 0.3
    
    # Ûµ. ØªÙØ³ÛŒØ± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ (Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ CLV)
    print("\nğŸ“Š Interpreting clusters...")
    cluster_names = engine.interpret_clusters_with_clv(clustered_df)
    
    # Û¶. Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
    print("\nğŸ“ˆ Generating visualizations...")
    engine.plot_clv_analysis(clustered_df, cluster_names)
    
    # Û·. Ú¯Ø²Ø§Ø±Ø´ Ø§Ø¬Ø±Ø§ÛŒÛŒ
    print("\nğŸ“‹ Generating executive report...")
    engine.generate_executive_report(clustered_df, cluster_names)
    
    # Û¸. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
    print("\nğŸ’¾ Saving models...")
    engine.save_models(clustered_df, kmeans_model, scaler, cluster_names, clv_models)
    
    print("\nâœ… Analysis complete!")
    print(f"ğŸ“ All files saved in: {OUTPUT_DIR}")

if __name__ == '__main__':
    main()